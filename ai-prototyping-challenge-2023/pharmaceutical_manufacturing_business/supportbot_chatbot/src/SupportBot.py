from langchain import PromptTemplate, LLMChain
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.indexes import VectorstoreIndexCreator
from langchain.embeddings import HuggingFaceEmbeddings
from datasets import load_dataset
from pathlib import Path

import pandas as pd
import os

class SupportBot():
    
    def __init__(self, data, model):
        self.data = data
        self.model = model
        
        
    def data_proc(self):
        
        if not os.path.isfile(self.data): 
            # Download the customer service robot support dialogue from hugging face
            dataset = load_dataset("FunDialogues/customer-service-robot-support")

            # Convert the dataset to a pandas dataframe
            dialogues = dataset['train']
            df = pd.DataFrame(dialogues, columns=['id', 'description', 'dialogue'])

            # Print the first 5 rows of the dataframe
            df.head()

            dialog = []
            # only keep the dialogue column
            dialog_df = df['dialogue']
            
            # save the data to txt file
            dialog_df.to_csv(self.data, sep=' ', index=False)
        else:
            print('data already exists in path.')

    def create_vectorstore(self, chunk_size: int = 500, overlap: int = 25):
        loader = TextLoader(self.data)
        # Text Splitter
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)
        # Embed the document and store into chroma DB
        self.index = VectorstoreIndexCreator(embedding= HuggingFaceEmbeddings(), text_splitter=text_splitter).from_loaders([loader])


    def inference(self, user_input: str, context_verbosity: bool = False, top_k: int=2):
        # perform similarity search and retrieve the context from our documents
        results = self.index.vectorstore.similarity_search(user_input, k=top_k)
        # join all context information (top 4) into one string 
        context = "\n".join([document.page_content for document in results])
        if context_verbosity:
            print(f"Retrieving information related to your question...")
            print(f"Found this content which is most similar to your question: {context}")

        template = """
        Please use the following robotic technical support related questions to answer questions. 
        Context: {context}
        ---
        This is the user's question: {question}
        Answer: This is what our robot arm technical specialist suggest."""

        prompt = PromptTemplate(template=template, input_variables=["context", "question"]).partial(context=context)

        llm_chain = LLMChain(prompt=prompt, llm=self.model)
        print("Processing the information with gpt4all...\n")
        response = llm_chain.run(user_input)
        return response