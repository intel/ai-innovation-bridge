# Enabling AI Workloads and Optimizations on Intel Hardware with Hugging Face

Welcome to the repository for the workshop "Enabling AI Workloads and Optimizations on Intel Hardware with Hugging Face," originally delivered on January 3, 2024. This workshop provides comprehensive insights and practical examples of leveraging various Intel optimizations in conjunction with Hugging Face's powerful tools and libraries for AI development.

## Overview

The workshop covers a range of optimizations available for Intel software and hardware, aiming to enhance AI model performance significantly. Participants will explore the Intel Extension for PyTorch, OpenVINO, Intel Neural Compressor, Optimum Habana, and the Intel Extension for Transformers, through a series of detailed Jupyter notebooks.

## Repository Structure

This repository contains a total of 6 notebooks, each designed to guide you through different aspects of utilizing Intel optimizations with Hugging Face technologies:

### 1 - Introduction to Hugging Face - Understanding Model Loading and Inference
- **Description:** An easy introduction to accessing and inferring models using Hugging Face tools.

### 2 - Leveraging Intel Optimizations with Hugging Face for Enhanced Model Performance
- **Description:** Demonstrates how to improve training performance by utilizing Intel Extension for PyTorch.

### 3 - Harnessing Intel Optimizations for Efficient Model Quantization with Hugging Face
- **Description:** Guides on using Optimum Intel to perform dynamic quantization for enhanced model inference performance.

### 4 - ITREX - Leveraging Intel Optimizations for Enhanced Inference with Hugging Face
- **Description:** Shows how to use the Intel Extension for Transformers to optimize inference by loading models in INT4 precision.

### 5 - Enhancing Inference Performance with Optimum Intel and OpenVINO
- **Description:** Explains how to utilize Optimum Intel alongside the OpenVINO toolkit for optimized model inference.

### 6 - Uploading and Sharing Models on Hugging Face Hub with Intel Optimizations
- **Description:** Demonstrates the process of sharing a trained model with optimizations on the Hugging Face Hub, contributing to the open-source community.

## Getting Started

To begin working with these notebooks, ensure you have:

- Account on the intel developer cloud cloud.intel.com 
- An environment capable of running Jupyter notebooks (e.g., JupyterLab, VSCode, etc.)
- Python 3.8 or later installed

